{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74de102-0741-47f6-be0e-b82e11f8a8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ------------\n",
      "aiodns                    3.6.0\n",
      "aiohappyeyeballs          2.6.1\n",
      "aiohttp                   3.13.2\n",
      "aiosignal                 1.4.0\n",
      "anyio                     4.11.0\n",
      "argon2-cffi               25.1.0\n",
      "argon2-cffi-bindings      25.1.0\n",
      "arrow                     1.4.0\n",
      "asttokens                 3.0.1\n",
      "async-lru                 2.0.5\n",
      "async-timeout             5.0.1\n",
      "attrs                     25.4.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.14.2\n",
      "bleach                    6.3.0\n",
      "blinker                   1.9.0\n",
      "Brotli                    1.2.0\n",
      "cached-property           1.5.2\n",
      "ccxt                      4.5.26\n",
      "certifi                   2025.11.12\n",
      "cffi                      2.0.0\n",
      "charset-normalizer        3.4.4\n",
      "click                     8.3.1\n",
      "coincurve                 21.0.0\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.3\n",
      "contourpy                 1.3.2\n",
      "cryptography              46.0.3\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.17\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "duckduckgo_search         8.1.1\n",
      "exceptiongroup            1.3.1\n",
      "executing                 2.2.1\n",
      "fastjsonschema            2.21.2\n",
      "filelock                  3.19.1\n",
      "Flask                     3.1.2\n",
      "flask-cors                6.0.1\n",
      "fonttools                 4.61.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.8.0\n",
      "fsspec                    2025.9.0\n",
      "greenlet                  3.3.0\n",
      "h11                       0.16.0\n",
      "h2                        4.3.0\n",
      "hpack                     4.1.0\n",
      "html2text                 2025.4.15\n",
      "httpcore                  1.0.9\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.36.0\n",
      "hyperframe                6.1.0\n",
      "idna                      3.11\n",
      "importlib_metadata        8.7.0\n",
      "importlib_resources       6.5.2\n",
      "ipykernel                 7.1.0\n",
      "ipython                   8.37.0\n",
      "isoduration               20.11.0\n",
      "itsdangerous              2.2.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "joblib                    1.5.2\n",
      "json5                     0.12.1\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.25.1\n",
      "jsonschema-specifications 2025.9.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.9.1\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.3.0\n",
      "jupyter_server            2.17.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.5.0\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.28.0\n",
      "kiwisolver                1.4.9\n",
      "lark                      1.3.1\n",
      "lxml                      6.0.2\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.10.7\n",
      "matplotlib-inline         0.2.1\n",
      "mistune                   3.1.4\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.7.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest_asyncio              1.6.0\n",
      "networkx                  3.3\n",
      "notebook                  7.5.0\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.1.2\n",
      "overrides                 7.7.0\n",
      "packaging                 25.0\n",
      "pandas                    2.3.3\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.5\n",
      "pickleshare               0.7.5\n",
      "pillow                    11.3.0\n",
      "pip                       25.3\n",
      "platformdirs              4.5.0\n",
      "playwright                1.57.0\n",
      "primp                     0.15.0\n",
      "prometheus_client         0.23.1\n",
      "prompt_toolkit            3.0.52\n",
      "propcache                 0.4.1\n",
      "psutil                    7.1.3\n",
      "pure_eval                 0.2.3\n",
      "pycares                   4.11.0\n",
      "pycparser                 2.22\n",
      "pyee                      13.0.0\n",
      "Pygments                  2.19.2\n",
      "pyparsing                 3.2.5\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytrends                  4.9.2\n",
      "pytz                      2025.2\n",
      "pywin32                   311\n",
      "pywinpty                  2.0.15\n",
      "PyYAML                    6.0.3\n",
      "pyzmq                     27.1.0\n",
      "referencing               0.37.0\n",
      "regex                     2025.11.3\n",
      "requests                  2.32.5\n",
      "rfc3339_validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rfc3987-syntax            1.1.0\n",
      "rpds-py                   0.29.0\n",
      "safetensors               0.7.0\n",
      "scikit-learn              1.7.2\n",
      "scipy                     1.15.3\n",
      "Send2Trash                1.8.3\n",
      "setuptools                80.9.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.8\n",
      "stack_data                0.6.3\n",
      "sympy                     1.13.1\n",
      "ta                        0.11.0\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.6.0\n",
      "tinycss2                  1.5.0\n",
      "tokenizers                0.22.1\n",
      "tomli                     2.3.0\n",
      "torch                     2.6.0+cu124\n",
      "torchaudio                2.6.0+cu124\n",
      "torchvision               0.21.0+cu124\n",
      "tornado                   6.5.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.57.3\n",
      "typing_extensions         4.15.0\n",
      "typing_utils              0.1.0\n",
      "tzdata                    2025.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.5.0\n",
      "wcwidth                   0.2.14\n",
      "webcolors                 25.10.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.9.0\n",
      "Werkzeug                  3.1.4\n",
      "wheel                     0.45.1\n",
      "win_inet_pton             1.1.0\n",
      "yarl                      1.22.0\n",
      "zipp                      3.23.0\n",
      "zstandard                 0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d175761-ea67-4579-bbce-602690d45170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830c646a-3b68-43e8-86ff-c22c2fa832b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88dfcd7-eacb-4749-a4ca-384611302076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\recsys_crypto\\\\notebooks'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0287f346-cec6-49e3-b08c-af3ef8dfeb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\user\\Desktop\\recsys_crypto\n",
      "Folders and __init__.py created.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# You are in .../recsys_crypto/notebooks\n",
    "project_root = Path.cwd().parent\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "# Folders to create\n",
    "folders = [\n",
    "    \"src\",\n",
    "    \"src/__pycache__\",   # will fill itself when you run code\n",
    "    \"data/raw/ohlcv\",\n",
    "    \"data/raw/news\",\n",
    "    \"data/processed\",\n",
    "    \"data/patterns\",\n",
    "    \"models/ml\",\n",
    "    \"models/configs\",\n",
    "    \"scripts\",\n",
    "    \"tools\",\n",
    "]\n",
    "\n",
    "for f in folders:\n",
    "    p = project_root / f\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create __init__.py for packages\n",
    "for pkg in [\"src\", \"scripts\"]:\n",
    "    init_path = project_root / pkg / \"__init__.py\"\n",
    "    if not init_path.exists():\n",
    "        init_path.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Folders and __init__.py created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff51e990-15eb-4250-9ebd-6dcab08549d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/ollama_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/ollama_client.py\n",
    "# src/ollama_client.py\n",
    "\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    # If you have this in your config already\n",
    "    from .config import OLLAMA_MODEL_DEFAULT\n",
    "except Exception:\n",
    "    OLLAMA_MODEL_DEFAULT = \"gemma3:4b\"\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "# Reuse a single HTTP session for performance\n",
    "_SESSION = requests.Session()\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a trading assistant.\n",
    "\n",
    "You will receive structured market data for a single crypto asset at a specific time:\n",
    "- Price (open, high, low, close)\n",
    "- Volume\n",
    "- Technical indicators (RSI, MACD, moving averages, Bollinger bands, volatility)\n",
    "- Simple sentiment summary\n",
    "\n",
    "Your task:\n",
    "1. Decide how attractive it is to BUY, HOLD, or SELL this asset.\n",
    "2. Output a single JSON object with this exact schema:\n",
    "\n",
    "{\n",
    "  \"action_scores\": {\n",
    "    \"Buy\": 0.0-1.0,\n",
    "    \"Hold\": 0.0-1.0,\n",
    "    \"Sell\": 0.0-1.0\n",
    "  },\n",
    "  \"forecast\": \"bullish\" | \"bearish\" | \"neutral\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"reason\": \"short explanation\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- The three scores do NOT need to sum to 1.0, but must each be between 0.0 and 1.0.\n",
    "- Be consistent: if forecast is \"bullish\", Buy usually should have a higher score than Sell.\n",
    "- Return ONLY the JSON object. No markdown, no extra text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_user_content(row: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Turn a feature row into a text description for the LLM.\n",
    "\n",
    "    This function expects keys like:\n",
    "        asset, timestamp, open, high, low, close, volume,\n",
    "        rsi, macd, macd_signal,\n",
    "        sma_7, sma_30,\n",
    "        bb_high, bb_low,\n",
    "        returns_1h, volatility_24h,\n",
    "        sentiment_summary (optional).\n",
    "    \"\"\"\n",
    "    asset = row.get(\"asset\", \"UNKNOWN\")\n",
    "    ts = row.get(\"timestamp\", \"UNKNOWN\")\n",
    "\n",
    "    open_price = row.get(\"open\", None)\n",
    "    high = row.get(\"high\", None)\n",
    "    low = row.get(\"low\", None)\n",
    "    close = row.get(\"close\", None)\n",
    "    volume = row.get(\"volume\", None)\n",
    "\n",
    "    rsi = row.get(\"rsi\", None)\n",
    "    macd = row.get(\"macd\", None)\n",
    "    macd_signal = row.get(\"macd_signal\", None)\n",
    "    sma7 = row.get(\"sma_7\", None)\n",
    "    sma30 = row.get(\"sma_30\", None)\n",
    "    bb_high = row.get(\"bb_high\", None)\n",
    "    bb_low = row.get(\"bb_low\", None)\n",
    "    ret_1h = row.get(\"returns_1h\", None)\n",
    "    vol_24h = row.get(\"volatility_24h\", None)\n",
    "\n",
    "    sentiment = row.get(\"sentiment_summary\", \"No sentiment data available.\")\n",
    "\n",
    "    lines = [\n",
    "        f\"Asset: {asset}\",\n",
    "        f\"Timestamp: {ts}\",\n",
    "        \"\",\n",
    "        \"Price & Volume:\",\n",
    "        f\"- Open: {open_price}\",\n",
    "        f\"- High: {high}\",\n",
    "        f\"- Low: {low}\",\n",
    "        f\"- Close: {close}\",\n",
    "        f\"- Volume: {volume}\",\n",
    "        \"\",\n",
    "        \"Technical indicators:\",\n",
    "        f\"- RSI: {rsi}\",\n",
    "        f\"- MACD: {macd}\",\n",
    "        f\"- MACD Signal: {macd_signal}\",\n",
    "        f\"- SMA 7: {sma7}\",\n",
    "        f\"- SMA 30: {sma30}\",\n",
    "        f\"- Bollinger High: {bb_high}\",\n",
    "        f\"- Bollinger Low: {bb_low}\",\n",
    "        f\"- 1h Returns: {ret_1h}\",\n",
    "        f\"- 24h Volatility (std of returns): {vol_24h}\",\n",
    "        \"\",\n",
    "        \"Sentiment summary:\",\n",
    "        f\"{sentiment}\",\n",
    "        \"\",\n",
    "        \"Based on this information, estimate how attractive it is to BUY, HOLD, or SELL this asset now.\",\n",
    "        \"Return ONLY the JSON object with fields action_scores, forecast, confidence, reason.\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Robust JSON extraction\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "def _try_json_direct(text: str) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _try_json_braces(text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Try to find a top-level {...} block by matching braces.\n",
    "    \"\"\"\n",
    "    start = -1\n",
    "    depth = 0\n",
    "    for i, ch in enumerate(text):\n",
    "        if ch == \"{\":\n",
    "            if depth == 0:\n",
    "                start = i\n",
    "            depth += 1\n",
    "        elif ch == \"}\":\n",
    "            depth -= 1\n",
    "            if depth == 0 and start != -1:\n",
    "                candidate = text[start : i + 1]\n",
    "                try:\n",
    "                    return json.loads(candidate)\n",
    "                except Exception:\n",
    "                    # continue searching in case there is another valid block\n",
    "                    start = -1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _try_json_regex(text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fallback: use regex to find the first {...} substring and parse it.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"\\{.*\\}\", re.DOTALL)\n",
    "    match = pattern.search(text)\n",
    "    if not match:\n",
    "        return None\n",
    "    candidate = match.group(0)\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _fallback_from_text(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Last-resort extraction if JSON parsing fails completely.\n",
    "\n",
    "    We try to guess Buy/Hold/Sell scores and forecast/confidence\n",
    "    from any numbers and keywords in the text.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    def find_score(keyword: str) -> float:\n",
    "        # Look for keyword followed by a number like 0.7 or 70%\n",
    "        pattern = re.compile(rf\"{keyword}[^0-9]*([0-9]+(\\.[0-9]+)?)\", re.IGNORECASE)\n",
    "        m = pattern.search(text)\n",
    "        if not m:\n",
    "            return 0.0\n",
    "        try:\n",
    "            val = float(m.group(1))\n",
    "            if val > 1.0:\n",
    "                val = val / 100.0\n",
    "            return max(0.0, min(1.0, val))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    buy_score = find_score(\"buy\")\n",
    "    hold_score = find_score(\"hold\")\n",
    "    sell_score = find_score(\"sell\")\n",
    "\n",
    "    if buy_score == hold_score == sell_score == 0.0:\n",
    "        # Fallback neutral\n",
    "        buy_score = hold_score = sell_score = 1.0 / 3.0\n",
    "\n",
    "    if \"bullish\" in text_lower:\n",
    "        forecast = \"bullish\"\n",
    "    elif \"bearish\" in text_lower:\n",
    "        forecast = \"bearish\"\n",
    "    else:\n",
    "        forecast = \"neutral\"\n",
    "\n",
    "    confidence = 0.5\n",
    "\n",
    "    return {\n",
    "        \"action_scores\": {\n",
    "            \"Buy\": float(buy_score),\n",
    "            \"Hold\": float(hold_score),\n",
    "            \"Sell\": float(sell_score),\n",
    "        },\n",
    "        \"forecast\": forecast,\n",
    "        \"confidence\": confidence,\n",
    "        \"reason\": \"Fallback extraction from non-JSON response.\",\n",
    "    }\n",
    "\n",
    "\n",
    "def _extract_json(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Try multiple strategies to pull a JSON object out of LLM output.\n",
    "    \"\"\"\n",
    "    for fn in (_try_json_direct, _try_json_braces, _try_json_regex):\n",
    "        obj = fn(text)\n",
    "        if obj is not None:\n",
    "            return obj\n",
    "    # If everything failed, do heuristic fallback\n",
    "    return _fallback_from_text(text)\n",
    "\n",
    "\n",
    "# --------------\n",
    "# Main API call\n",
    "# --------------\n",
    "\n",
    "\n",
    "def ask_ollama(\n",
    "    model_name: str,\n",
    "    row: Dict[str, Any],\n",
    "    timeout: int = 120,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Call Ollama with given model and one feature row.\n",
    "\n",
    "    Returns a dict with keys:\n",
    "        - action_scores: {\"Buy\": float, \"Hold\": float, \"Sell\": float}\n",
    "        - forecast: str\n",
    "        - confidence: float\n",
    "        - reason: str\n",
    "    \"\"\"\n",
    "    user_content = build_user_content(row)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model_name or OLLAMA_MODEL_DEFAULT,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "    }\n",
    "\n",
    "    resp = _SESSION.post(OLLAMA_URL, json=payload, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    data = resp.json()\n",
    "    # Ollama's chat API returns {\"message\": {\"content\": \"...\"}, ...}\n",
    "    content = \"\"\n",
    "    if isinstance(data, dict):\n",
    "        msg = data.get(\"message\") or data.get(\"choices\", [{}])[0]\n",
    "        if isinstance(msg, dict):\n",
    "            content = msg.get(\"content\", \"\") or msg.get(\"text\", \"\")\n",
    "    if not content:\n",
    "        raise ValueError(\"Empty response from Ollama\")\n",
    "\n",
    "    parsed = _extract_json(content)\n",
    "\n",
    "    # Ensure structure\n",
    "    scores = parsed.get(\"action_scores\", {})\n",
    "    for k in (\"Buy\", \"Hold\", \"Sell\"):\n",
    "        scores.setdefault(k, 0.0)\n",
    "\n",
    "    parsed[\"action_scores\"] = {\n",
    "        \"Buy\": float(scores[\"Buy\"]),\n",
    "        \"Hold\": float(scores[\"Hold\"]),\n",
    "        \"Sell\": float(scores[\"Sell\"]),\n",
    "    }\n",
    "    parsed.setdefault(\"forecast\", \"neutral\")\n",
    "    parsed.setdefault(\"confidence\", 0.5)\n",
    "    parsed.setdefault(\"reason\", \"\")\n",
    "\n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cac1688-8f02-47f8-9b8f-3f24b224f80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/__init__.py\n",
    "# Make src a package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b569268d-f7a5-4cae-90eb-64512130c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/config.py\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root = .../recsys_crypto\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = str(PROJECT_ROOT / \"data\")\n",
    "\n",
    "# SPMF jar path (if/when you use it)\n",
    "SPMF_JAR_PATH = str(PROJECT_ROOT / \"tools\" / \"spmf.jar\")\n",
    "\n",
    "# Default Ollama model (change as you like: \"llama3\", \"gemma2:9b\", \"phi3\", etc.)\n",
    "OLLAMA_MODEL_DEFAULT = \"mistral\"\n",
    "\n",
    "# Exchange + assets settings\n",
    "ASSETS = [\n",
    "    \"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\", \"XRPUSDT\",\n",
    "    \"DOGEUSDT\", \"ADAUSDT\", \"AVAXUSDT\", \"TRXUSDT\", \"LINKUSDT\",\n",
    "]\n",
    "\n",
    "EXCHANGE = \"binance\"\n",
    "TIMEFRAME = \"1h\"\n",
    "WINDOW_DAYS = 45          # ~45 days history\n",
    "HORIZON_HOURS = 72        # 3 days -> 72 hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bbd96f6-d5ce-4f4b-9fae-5ada176a0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/market_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/market_data.py\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ta.trend import MACD, SMAIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "\n",
    "from .config import ASSETS, EXCHANGE, TIMEFRAME, WINDOW_DAYS, DATA_DIR\n",
    "\n",
    "\n",
    "def get_exchange():\n",
    "    return getattr(ccxt, EXCHANGE)()\n",
    "\n",
    "\n",
    "def fetch_ohlcv_for_symbol(exchange, symbol: str, limit: int | None = None) -> pd.DataFrame:\n",
    "    if limit is None:\n",
    "        limit = WINDOW_DAYS * 24  # rough for 1h data\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe=TIMEFRAME, limit=limit)\n",
    "    df = pd.DataFrame(\n",
    "        ohlcv,\n",
    "        columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"],\n",
    "    )\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"rsi\"] = RSIIndicator(df[\"close\"], window=14).rsi()\n",
    "\n",
    "    macd = MACD(df[\"close\"])\n",
    "    df[\"macd\"] = macd.macd()\n",
    "    df[\"macd_signal\"] = macd.macd_signal()\n",
    "\n",
    "    df[\"sma_7\"] = SMAIndicator(df[\"close\"], window=7).sma_indicator()\n",
    "    df[\"sma_30\"] = SMAIndicator(df[\"close\"], window=30).sma_indicator()\n",
    "\n",
    "    bb = BollingerBands(df[\"close\"], window=20)\n",
    "    df[\"bb_high\"] = bb.bollinger_hband()\n",
    "    df[\"bb_low\"] = bb.bollinger_lband()\n",
    "\n",
    "    df[\"returns_1h\"] = df[\"close\"].pct_change()\n",
    "    df[\"volatility_24h\"] = df[\"returns_1h\"].rolling(24).std()\n",
    "\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_market_feature_table() -> pd.DataFrame:\n",
    "    data_path = Path(DATA_DIR) / \"processed\"\n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    exchange = get_exchange()\n",
    "    all_frames = []\n",
    "\n",
    "    for symbol in ASSETS:\n",
    "        symbol_with_slash = symbol.replace(\"USDT\", \"/USDT\")\n",
    "        df = fetch_ohlcv_for_symbol(exchange, symbol_with_slash)\n",
    "        df = add_technical_indicators(df)\n",
    "        df[\"asset\"] = symbol\n",
    "        all_frames.append(df)\n",
    "\n",
    "    full = pd.concat(all_frames, ignore_index=True)\n",
    "    out_file = data_path / \"market_features.csv\"\n",
    "    full.to_csv(out_file, index=False)\n",
    "    print(f\"Saved market features to {out_file}\")\n",
    "    return full\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_market_feature_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d09f664-0819-485f-92f6-384160746749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/user_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/user_model.py\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "RiskLevel = Literal[\"low\", \"moderate\", \"high\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserProfile:\n",
    "    \"\"\"\n",
    "    Simple user profile capturing a name and risk preference.\n",
    "\n",
    "    risk_level:\n",
    "        - \"low\":      conservative / risk-averse\n",
    "        - \"moderate\": balanced\n",
    "        - \"high\":     aggressive / risk-seeking\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    risk_level: RiskLevel   # 'low', 'moderate', 'high'\n",
    "\n",
    "    @classmethod\n",
    "    def from_type(cls, user_type: str) -> \"UserProfile\":\n",
    "        \"\"\"\n",
    "        Factory for convenient construction from a simple string.\n",
    "\n",
    "        Examples:\n",
    "            UserProfile.from_type(\"conservative\") -> (\"Conservative\", \"low\")\n",
    "            UserProfile.from_type(\"moderate\")     -> (\"Moderate\", \"moderate\")\n",
    "            UserProfile.from_type(\"aggressive\")   -> (\"Aggressive\", \"high\")\n",
    "        \"\"\"\n",
    "        t = (user_type or \"\").strip().lower()\n",
    "\n",
    "        if t in (\"conservative\", \"low\", \"risk_low\", \"risk-averse\", \"risk_averse\"):\n",
    "            return cls(name=\"Conservative\", risk_level=\"low\")\n",
    "\n",
    "        if t in (\"aggressive\", \"high\", \"risk_high\", \"risk-seeking\", \"risk_seeking\"):\n",
    "            return cls(name=\"Aggressive\", risk_level=\"high\")\n",
    "\n",
    "        # default: moderate\n",
    "        return cls(name=\"Moderate\", risk_level=\"moderate\")\n",
    "\n",
    "\n",
    "# Optional handy constants (keeps your old style)\n",
    "CONSERVATIVE = UserProfile(\"Conservative\", \"low\")\n",
    "MODERATE = UserProfile(\"Moderate\", \"moderate\")\n",
    "AGGRESSIVE = UserProfile(\"Aggressive\", \"high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bce1a2a-eac0-4ee3-98b3-b554640915e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/hybrid_engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/hybrid_engine.py\n",
    "from typing import Dict\n",
    "from .user_model import UserProfile\n",
    "\n",
    "\n",
    "def compute_final_scores(\n",
    "    ml_conf: Dict[str, float],\n",
    "    llm_score: Dict[str, float],\n",
    "    pattern_support: Dict[str, float],\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    gamma: float,\n",
    "    user: UserProfile,\n",
    ") -> Dict[str, float]:\n",
    "    actions = [\"Buy\", \"Hold\", \"Sell\"]\n",
    "    scores: Dict[str, float] = {}\n",
    "\n",
    "    for act in actions:\n",
    "        base = (\n",
    "            alpha * ml_conf.get(act, 0.0) +\n",
    "            beta * llm_score.get(act, 0.0) +\n",
    "            gamma * pattern_support.get(act, 0.0)\n",
    "        )\n",
    "\n",
    "        # user risk adjustment\n",
    "        if user.risk_level == \"low\":\n",
    "            if act == \"Buy\":\n",
    "                base *= 0.7\n",
    "            elif act == \"Sell\":\n",
    "                base *= 1.1\n",
    "        elif user.risk_level == \"high\":\n",
    "            if act == \"Buy\":\n",
    "                base *= 1.2\n",
    "            elif act == \"Sell\":\n",
    "                base *= 1.1\n",
    "            elif act == \"Hold\":\n",
    "                base *= 0.8\n",
    "\n",
    "        scores[act] = base\n",
    "\n",
    "    total = sum(scores.values()) or 1.0\n",
    "    for k in scores:\n",
    "        scores[k] /= total\n",
    "    return scores\n",
    "\n",
    "\n",
    "def rank_actions(scores: Dict[str, float]):\n",
    "    return sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc878c9b-5f31-425c-a537-f8885d74dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/recsys_metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/recsys_metrics.py\n",
    "from typing import List, Dict\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def _relevance(action: str, true_action: str) -> int:\n",
    "    return int(action == true_action)\n",
    "\n",
    "\n",
    "def ndcg_at_k(records: List[Dict], k: int) -> float:\n",
    "    scores = []\n",
    "    for rec in records:\n",
    "        ranking = rec[\"ranking\"][:k]\n",
    "        true = rec[\"true\"]\n",
    "        dcg = 0.0\n",
    "        for i, a in enumerate(ranking):\n",
    "            rel = _relevance(a, true)\n",
    "            dcg += (2**rel - 1) / math.log2(i + 2)\n",
    "        idcg = (2**1 - 1) / math.log2(1 + 1)\n",
    "        scores.append(dcg / idcg if idcg > 0 else 0.0)\n",
    "    return sum(scores) / len(scores) if scores else 0.0\n",
    "\n",
    "\n",
    "def map_at_k(records: List[Dict], k: int) -> float:\n",
    "    aps = []\n",
    "    for rec in records:\n",
    "        ranking = rec[\"ranking\"][:k]\n",
    "        true = rec[\"true\"]\n",
    "        if true in ranking:\n",
    "            idx = ranking.index(true)\n",
    "            aps.append(1.0 / (idx + 1))\n",
    "        else:\n",
    "            aps.append(0.0)\n",
    "    return sum(aps) / len(aps) if aps else 0.0\n",
    "\n",
    "\n",
    "def diversity(records: List[Dict]) -> float:\n",
    "    top1 = [r[\"ranking\"][0] for r in records if r[\"ranking\"]]\n",
    "    counts = Counter(top1)\n",
    "    total = sum(counts.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    entropy = -sum((c/total) * math.log2(c/total) for c in counts.values())\n",
    "    max_entropy = math.log2(len(counts)) if counts else 1.0\n",
    "    return entropy / max_entropy if max_entropy > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45985599-3305-4f65-b8ef-b879162ab66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/__init__.py\n",
    "# Make scripts a package (optional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b2e84e-b655-4715-9ca1-4dd0efd61a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../scripts/demo_recommend.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/demo_recommend.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from src.user_model import MODERATE\n",
    "from src.hybrid_engine import compute_final_scores, rank_actions\n",
    "from src.ollama_client import ask_ollama\n",
    "from src.config import DATA_DIR\n",
    "\n",
    "\n",
    "def main():\n",
    "    df_path = Path(DATA_DIR) / \"processed\" / \"market_features.csv\"\n",
    "    if not df_path.exists():\n",
    "        raise FileNotFoundError(f\"market_features.csv not found at {df_path}. \"\n",
    "                                f\"Run src.market_data.build_market_feature_table() first.\")\n",
    "\n",
    "    df = pd.read_csv(df_path)\n",
    "    row = df.iloc[-1].to_dict()  # last row as example\n",
    "\n",
    "    # placeholder ML & pattern signals (you will replace with real ones later)\n",
    "    ml_conf = {\"Buy\": 0.5, \"Hold\": 0.3, \"Sell\": 0.2}\n",
    "    pattern_support = {\"Buy\": 0.1, \"Hold\": 0.1, \"Sell\": 0.1}\n",
    "\n",
    "    model_name = \"mistral\"  # or \"llama3\", \"gemma2:9b\", \"phi3\"\n",
    "    llm_out = ask_ollama(model_name, row)\n",
    "    llm_scores = llm_out.get(\"action_scores\", {})\n",
    "\n",
    "    for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "        llm_scores.setdefault(a, 0.0)\n",
    "\n",
    "    user = MODERATE\n",
    "    scores = compute_final_scores(\n",
    "        ml_conf,\n",
    "        llm_scores,\n",
    "        pattern_support,\n",
    "        alpha=0.4,\n",
    "        beta=0.4,\n",
    "        gamma=0.2,\n",
    "        user=user,\n",
    "    )\n",
    "    ranking = rank_actions(scores)\n",
    "\n",
    "    print(\"User profile:\", user.name)\n",
    "    print(\"LLM scores:\", llm_scores)\n",
    "    print(\"Final scores:\", scores)\n",
    "    print(\"Ranking:\", ranking)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8fb7b7-d792-4b7b-a17f-f23d87fbf612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market_data: C:\\Users\\user\\Desktop\\recsys_crypto\\src\\market_data.py\n",
      "ollama_client: C:\\Users\\user\\Desktop\\recsys_crypto\\src\\ollama_client.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src import market_data, ollama_client, hybrid_engine, user_model\n",
    "\n",
    "print(\"market_data:\", market_data.__file__)\n",
    "print(\"ollama_client:\", ollama_client.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f868b23-e046-4784-84a7-80e053984e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\user\\Desktop\\recsys_crypto\n",
      "DATA_DIR: C:\\Users\\user\\Desktop\\recsys_crypto\\data\n",
      "Saved market features to C:\\Users\\user\\Desktop\\recsys_crypto\\data\\processed\\market_features.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>sma_7</th>\n",
       "      <th>sma_30</th>\n",
       "      <th>bb_high</th>\n",
       "      <th>bb_low</th>\n",
       "      <th>returns_1h</th>\n",
       "      <th>volatility_24h</th>\n",
       "      <th>asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-31 10:00:00</td>\n",
       "      <td>109848.39</td>\n",
       "      <td>110117.32</td>\n",
       "      <td>109710.08</td>\n",
       "      <td>109819.20</td>\n",
       "      <td>375.06762</td>\n",
       "      <td>54.808341</td>\n",
       "      <td>171.940629</td>\n",
       "      <td>3.423187</td>\n",
       "      <td>109830.358571</td>\n",
       "      <td>109053.284667</td>\n",
       "      <td>110923.274230</td>\n",
       "      <td>106497.317770</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-31 11:00:00</td>\n",
       "      <td>109819.21</td>\n",
       "      <td>110550.00</td>\n",
       "      <td>109461.53</td>\n",
       "      <td>110415.61</td>\n",
       "      <td>712.18313</td>\n",
       "      <td>59.211415</td>\n",
       "      <td>235.736423</td>\n",
       "      <td>49.885834</td>\n",
       "      <td>109877.728571</td>\n",
       "      <td>109058.862000</td>\n",
       "      <td>111127.225528</td>\n",
       "      <td>106563.771472</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-31 12:00:00</td>\n",
       "      <td>110415.62</td>\n",
       "      <td>110681.00</td>\n",
       "      <td>109619.94</td>\n",
       "      <td>109653.19</td>\n",
       "      <td>904.10139</td>\n",
       "      <td>52.208584</td>\n",
       "      <td>222.212599</td>\n",
       "      <td>84.351187</td>\n",
       "      <td>109842.591429</td>\n",
       "      <td>109021.701333</td>\n",
       "      <td>111204.727181</td>\n",
       "      <td>106637.131819</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-31 13:00:00</td>\n",
       "      <td>109653.20</td>\n",
       "      <td>110240.00</td>\n",
       "      <td>109366.91</td>\n",
       "      <td>110157.54</td>\n",
       "      <td>1164.32028</td>\n",
       "      <td>55.922307</td>\n",
       "      <td>249.317721</td>\n",
       "      <td>117.344494</td>\n",
       "      <td>109915.097143</td>\n",
       "      <td>108981.395333</td>\n",
       "      <td>111299.205830</td>\n",
       "      <td>106809.738170</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-31 14:00:00</td>\n",
       "      <td>110157.54</td>\n",
       "      <td>111054.61</td>\n",
       "      <td>109590.46</td>\n",
       "      <td>110790.14</td>\n",
       "      <td>2487.24179</td>\n",
       "      <td>60.109395</td>\n",
       "      <td>318.176518</td>\n",
       "      <td>157.510899</td>\n",
       "      <td>110106.644286</td>\n",
       "      <td>108983.923000</td>\n",
       "      <td>111373.849274</td>\n",
       "      <td>107130.399726</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp       open       high        low      close      volume  \\\n",
       "0 2025-10-31 10:00:00  109848.39  110117.32  109710.08  109819.20   375.06762   \n",
       "1 2025-10-31 11:00:00  109819.21  110550.00  109461.53  110415.61   712.18313   \n",
       "2 2025-10-31 12:00:00  110415.62  110681.00  109619.94  109653.19   904.10139   \n",
       "3 2025-10-31 13:00:00  109653.20  110240.00  109366.91  110157.54  1164.32028   \n",
       "4 2025-10-31 14:00:00  110157.54  111054.61  109590.46  110790.14  2487.24179   \n",
       "\n",
       "         rsi        macd  macd_signal          sma_7         sma_30  \\\n",
       "0  54.808341  171.940629     3.423187  109830.358571  109053.284667   \n",
       "1  59.211415  235.736423    49.885834  109877.728571  109058.862000   \n",
       "2  52.208584  222.212599    84.351187  109842.591429  109021.701333   \n",
       "3  55.922307  249.317721   117.344494  109915.097143  108981.395333   \n",
       "4  60.109395  318.176518   157.510899  110106.644286  108983.923000   \n",
       "\n",
       "         bb_high         bb_low  returns_1h  volatility_24h    asset  \n",
       "0  110923.274230  106497.317770   -0.000266        0.005683  BTCUSDT  \n",
       "1  111127.225528  106563.771472    0.005431        0.005742  BTCUSDT  \n",
       "2  111204.727181  106637.131819   -0.006905        0.005337  BTCUSDT  \n",
       "3  111299.205830  106809.738170    0.004600        0.005149  BTCUSDT  \n",
       "4  111373.849274  107130.399726    0.005743        0.005133  BTCUSDT  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.market_data import build_market_feature_table\n",
    "from src.config import DATA_DIR\n",
    "\n",
    "print(\"PROJECT_ROOT:\", project_root)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "\n",
    "df_features = build_market_feature_table()\n",
    "df_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2b1e6c0-be4a-43ab-a3c0-63ba982d5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled rows: 8950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>future_return</th>\n",
       "      <th>true_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>2025-10-31 10:00:00</td>\n",
       "      <td>0.6101</td>\n",
       "      <td>-0.061629</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>2025-10-31 11:00:00</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>-0.066472</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>2025-10-31 12:00:00</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>2025-10-31 13:00:00</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>-0.065214</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>2025-10-31 14:00:00</td>\n",
       "      <td>0.6176</td>\n",
       "      <td>-0.063795</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asset           timestamp   close  future_return true_action\n",
       "0  ADAUSDT 2025-10-31 10:00:00  0.6101      -0.061629        Sell\n",
       "1  ADAUSDT 2025-10-31 11:00:00  0.6168      -0.066472        Sell\n",
       "2  ADAUSDT 2025-10-31 12:00:00  0.6117      -0.059506        Sell\n",
       "3  ADAUSDT 2025-10-31 13:00:00  0.6149      -0.065214        Sell\n",
       "4  ADAUSDT 2025-10-31 14:00:00  0.6176      -0.063795        Sell"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.config import HORIZON_HOURS\n",
    "\n",
    "features_path = Path(DATA_DIR) / \"processed\" / \"market_features.csv\"\n",
    "df = pd.read_csv(features_path, parse_dates=[\"timestamp\"])\n",
    "\n",
    "# sort by asset + time\n",
    "df = df.sort_values([\"asset\", \"timestamp\"])\n",
    "\n",
    "# compute future close after HORIZON_HOURS\n",
    "df[\"future_close\"] = df.groupby(\"asset\")[\"close\"].shift(-HORIZON_HOURS)\n",
    "df[\"future_return\"] = (df[\"future_close\"] - df[\"close\"]) / df[\"close\"]\n",
    "\n",
    "def true_action_from_return(r: float) -> str:\n",
    "    if r > 0.01:\n",
    "        return \"Buy\"\n",
    "    elif r < -0.01:\n",
    "        return \"Sell\"\n",
    "    else:\n",
    "        return \"Hold\"\n",
    "\n",
    "df[\"true_action\"] = df[\"future_return\"].apply(true_action_from_return)\n",
    "\n",
    "# drop last rows where future_close is NaN\n",
    "df_labeled = df.dropna(subset=[\"future_close\", \"true_action\"]).reset_index(drop=True)\n",
    "print(\"Labeled rows:\", len(df_labeled))\n",
    "df_labeled[[\"asset\", \"timestamp\", \"close\", \"future_return\", \"true_action\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f93ee25-ec6b-460c-b5ba-6656bb5baa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action_scores': {'Buy': 0.74, 'Hold': 0.23, 'Sell': 0.03},\n",
       " 'forecast': 'bullish',\n",
       " 'confidence': 0.85,\n",
       " 'reason': 'Strong short-term indicators and neutral sentiment support a bullish outlook.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ollama_client import ask_ollama\n",
    "\n",
    "# pick one row as example\n",
    "row_example = df_labeled.iloc[-1].to_dict()  # last row\n",
    "model_name = \"llama3\"  # or \"llama3\", or your Gemma tag from `ollama list`\n",
    "\n",
    "llm_output = ask_ollama(model_name, row_example)\n",
    "llm_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad6fa8ad-029e-4d4e-b968-759709f6181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3:4b -> {'action_scores': {'Buy': 0.45, 'Hold': 0.5, 'Sell': 0.05}, 'forecast': 'bullish', 'confidence': 0.65, 'reason': 'The RSI is moderately bullish, price is near SMA_7 and SMA_30, and recent sentiment is neutral. The price is consolidating, suggesting a potential upward move.'}\n",
      "llama3    -> {'action_scores': {'Buy': 0.0, 'Hold': 0.7, 'Sell': 0.3}, 'forecast': 'neutral', 'confidence': 0.6, 'reason': 'Mixed signals from indicators; RSI oversold, but MACD and SMAs indicate consolidation'}\n",
      "phi       -> {'action_scores': {'Buy': 0, 'Hold': 1, 'Sell': 0}, 'forecast': 'neutral', 'confidence': 1.0, 'reason': ''}\n"
     ]
    }
   ],
   "source": [
    "import importlib, sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import src.ollama_client as oc\n",
    "importlib.reload(oc)\n",
    "\n",
    "# quick single-call test\n",
    "row_debug = df_labeled.iloc[0].to_dict()\n",
    "print(\"gemma3:4b ->\", oc.ask_ollama(\"gemma3:4b\", row_debug))\n",
    "print(\"llama3    ->\", oc.ask_ollama(\"llama3\", row_debug))\n",
    "print(\"phi       ->\", oc.ask_ollama(\"phi\", row_debug))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c1ee602-0e74-46a9-a157-69d8ffcad0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing model: gemma3:4b ===\n",
      "\n",
      "=== Testing model: llama3 ===\n",
      "  [Error on row 0] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 5] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 9] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "\n",
      "=== Testing model: phi ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'gemma3:4b',\n",
       "  'accuracy': 0.2,\n",
       "  'avg_latency_sec': 1.7844038009643555,\n",
       "  'n_samples': 10,\n",
       "  'errors': 0},\n",
       " {'model': 'llama3',\n",
       "  'accuracy': 0.2857142857142857,\n",
       "  'avg_latency_sec': 2.6377481392451694,\n",
       "  'n_samples': 7,\n",
       "  'errors': 3},\n",
       " {'model': 'phi',\n",
       "  'accuracy': 0.2,\n",
       "  'avg_latency_sec': 8.044142150878907,\n",
       "  'n_samples': 10,\n",
       "  'errors': 0}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_test = [\n",
    "    \"gemma3:4b\",\n",
    "    \"llama3\",\n",
    "    \"phi\",\n",
    "]\n",
    "\n",
    "sample_size = 10\n",
    "sample = df_labeled.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n=== Testing model: {model_name} ===\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    latencies = []\n",
    "    errors = 0\n",
    "\n",
    "    for i, row in sample.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        start = time.time()\n",
    "        try:\n",
    "            out = oc.ask_ollama(model_name, row_dict)\n",
    "\n",
    "            scores = out.get(\"action_scores\", {})\n",
    "            for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "                scores.setdefault(a, 0.0)\n",
    "\n",
    "            pred_action = max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "\n",
    "            latency = time.time() - start\n",
    "            latencies.append(latency)\n",
    "            total += 1\n",
    "\n",
    "            if pred_action == row[\"true_action\"]:\n",
    "                correct += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            print(f\"  [Error on row {i}] {e}\")\n",
    "\n",
    "    accuracy = correct / total if total else 0.0\n",
    "    avg_latency = sum(latencies) / len(latencies) if latencies else None\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"avg_latency_sec\": avg_latency,\n",
    "        \"n_samples\": total,\n",
    "        \"errors\": errors,\n",
    "    })\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bba5e9c-fd85-49af-ae53-e3429b39ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in raw feature table:  9670\n",
      "Total rows in labeled table:      8950\n",
      "\n",
      "Rows per asset (labeled):\n",
      "asset\n",
      "ADAUSDT     895\n",
      "AVAXUSDT    895\n",
      "BNBUSDT     895\n",
      "BTCUSDT     895\n",
      "DOGEUSDT    895\n",
      "ETHUSDT     895\n",
      "LINKUSDT    895\n",
      "SOLUSDT     895\n",
      "TRXUSDT     895\n",
      "XRPUSDT     895\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Time range (labeled):\n",
      "Min timestamp: 2025-10-31 10:00:00\n",
      "Max timestamp: 2025-12-07 16:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows in raw feature table: \", len(df))\n",
    "print(\"Total rows in labeled table:     \", len(df_labeled))\n",
    "\n",
    "print(\"\\nRows per asset (labeled):\")\n",
    "print(df_labeled[\"asset\"].value_counts())\n",
    "\n",
    "print(\"\\nTime range (labeled):\")\n",
    "print(\"Min timestamp:\", df_labeled[\"timestamp\"].min())\n",
    "print(\"Max timestamp:\", df_labeled[\"timestamp\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26b492bc-4580-4054-943f-455bb2be5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for LLM comparison: 300\n",
      "asset\n",
      "ADAUSDT     30\n",
      "AVAXUSDT    30\n",
      "BNBUSDT     30\n",
      "BTCUSDT     30\n",
      "DOGEUSDT    30\n",
      "ETHUSDT     30\n",
      "LINKUSDT    30\n",
      "SOLUSDT     30\n",
      "TRXUSDT     30\n",
      "XRPUSDT     30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Testing model: gemma3:4b ===\n",
      "  [Error on row 61] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 64] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 65] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 67] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 80] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 81] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 82] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 84] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 96] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 108] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 109] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 116] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 122] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 128] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 129] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 130] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 131] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 136] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 142] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 143] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 146] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 157] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 165] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 166] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 172] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 180] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 185] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 186] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 197] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "  [Error on row 199] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43moc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     scores \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSell\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\Desktop\\recsys_crypto\\src\\ollama_client.py:226\u001b[0m, in \u001b[0;36mask_ollama\u001b[1;34m(model_name, row)\u001b[0m\n\u001b[0;32m    215\u001b[0m messages: List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    216\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: SYSTEM_PROMPT},\n\u001b[0;32m    217\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: build_user_content(row)},\n\u001b[0;32m    218\u001b[0m ]\n\u001b[0;32m    220\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    224\u001b[0m }\n\u001b[1;32m--> 226\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOLLAMA_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    228\u001b[0m data \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ai_env\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import src.ollama_client as oc  # make sure this is imported\n",
    "from importlib import reload\n",
    "reload(oc)  # ensure latest version is loaded\n",
    "\n",
    "# 1) build a balanced sample: 30 per asset  300 total\n",
    "n_per_asset = 30\n",
    "parts = []\n",
    "for asset, g in df_labeled.groupby(\"asset\"):\n",
    "    parts.append(g.sample(n=n_per_asset, random_state=42))\n",
    "sample = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "sample_size = len(sample)\n",
    "print(\"Sample size for LLM comparison:\", sample_size)\n",
    "print(sample[\"asset\"].value_counts())\n",
    "\n",
    "# 2) run comparison on this bigger sample\n",
    "models_to_test = [\n",
    "    \"gemma3:4b\",\n",
    "    \"llama3\",\n",
    "    \"phi\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n=== Testing model: {model_name} ===\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    latencies = []\n",
    "    errors = 0\n",
    "\n",
    "    for i, row in sample.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        start = time.time()\n",
    "        try:\n",
    "            out = oc.ask_ollama(model_name, row_dict)\n",
    "\n",
    "            scores = out.get(\"action_scores\", {})\n",
    "            for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "                scores.setdefault(a, 0.0)\n",
    "\n",
    "            pred_action = max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "\n",
    "            latency = time.time() - start\n",
    "            latencies.append(latency)\n",
    "            total += 1\n",
    "\n",
    "            if pred_action == row[\"true_action\"]:\n",
    "                correct += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            print(f\"  [Error on row {i}] {e}\")\n",
    "\n",
    "    accuracy = correct / total if total else 0.0\n",
    "    avg_latency = sum(latencies) / len(latencies) if latencies else None\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"avg_latency_sec\": avg_latency,\n",
    "        \"n_samples\": total,\n",
    "        \"errors\": errors,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075479d-a847-4549-9be5-e0fcc312f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ensure sorted\n",
    "df_labeled = df_labeled.sort_values([\"timestamp\", \"asset\"]).reset_index(drop=True)\n",
    "\n",
    "# time-based split: 70% earliest timestamps for training, 30% latest for test\n",
    "unique_times = df_labeled[\"timestamp\"].sort_values().unique()\n",
    "split_idx = int(len(unique_times) * 0.7)\n",
    "split_time = unique_times[split_idx]\n",
    "\n",
    "train_mask = df_labeled[\"timestamp\"] <= split_time\n",
    "test_mask = df_labeled[\"timestamp\"] > split_time\n",
    "\n",
    "df_train = df_labeled[train_mask].copy()\n",
    "df_test = df_labeled[test_mask].copy()\n",
    "\n",
    "print(\"Train rows:\", len(df_train), \"Test rows:\", len(df_test))\n",
    "print(\"Train period:\", df_train[\"timestamp\"].min(), \"\", df_train[\"timestamp\"].max())\n",
    "print(\"Test period:\", df_test[\"timestamp\"].min(), \"\", df_test[\"timestamp\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d98ed-98aa-45d7-a477-f87a28201087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick feature columns (exclude target and obvious IDs)\n",
    "exclude_cols = [\"timestamp\", \"asset\", \"future_close\", \"future_return\", \"true_action\"]\n",
    "feature_cols = [c for c in df_labeled.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[\"true_action\"]\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classes:\", clf.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa206130-b7da-4979-989e-61143af4d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hybrid_engine import compute_final_scores, rank_actions\n",
    "from src.recsys_metrics import ndcg_at_k, map_at_k\n",
    "from src.user_model import MODERATE  # or CONSERVATIVE / AGGRESSIVE\n",
    "\n",
    "import src.ollama_client as oc\n",
    "from importlib import reload\n",
    "reload(oc)\n",
    "\n",
    "user_profile = MODERATE\n",
    "model_name = \"gemma3:4b\"  # or \"llama3\", \"phi\"\n",
    "\n",
    "records = []    # for RecSys metrics\n",
    "pnl_returns = []  # optional: realized returns based on top action\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "\n",
    "    # 1) ML confidences\n",
    "    X_row = row[feature_cols].values.reshape(1, -1)\n",
    "    proba = clf.predict_proba(X_row)[0]\n",
    "    ml_conf = {cls: float(p) for cls, p in zip(clf.classes_, proba)}\n",
    "    # ensure all three keys exist\n",
    "    for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "        ml_conf.setdefault(a, 0.0)\n",
    "\n",
    "    # 2) LLM scores\n",
    "    llm_out = oc.ask_ollama(model_name, row_dict)\n",
    "    llm_scores = llm_out.get(\"action_scores\", {})\n",
    "    for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "        llm_scores.setdefault(a, 0.0)\n",
    "\n",
    "    # 3) Pattern support (placeholder for now)\n",
    "    pattern_support = {\"Buy\": 0.1, \"Hold\": 0.1, \"Sell\": 0.1}\n",
    "\n",
    "    # 4) Hybrid final scores & ranking\n",
    "    final_scores = compute_final_scores(\n",
    "        ml_conf,\n",
    "        llm_scores,\n",
    "        pattern_support,\n",
    "        alpha=0.4,   # ML weight\n",
    "        beta=0.4,    # LLM weight\n",
    "        gamma=0.2,   # pattern weight\n",
    "        user=user_profile,\n",
    "    )\n",
    "    ranking = [a for a, _ in rank_actions(final_scores)]\n",
    "\n",
    "    # 5) ground truth\n",
    "    true_action = row[\"true_action\"]\n",
    "    records.append({\"ranking\": ranking, \"true\": true_action})\n",
    "\n",
    "    # 6) simple PnL (optional):\n",
    "    # assume: if we \"Buy\", we take future_return; if \"Sell\", we take -future_return; if \"Hold\", 0\n",
    "    top_action = ranking[0]\n",
    "    fr = row[\"future_return\"]\n",
    "    if top_action == \"Buy\":\n",
    "        pnl = fr\n",
    "    elif top_action == \"Sell\":\n",
    "        pnl = -fr\n",
    "    else:\n",
    "        pnl = 0.0\n",
    "    pnl_returns.append(pnl)\n",
    "\n",
    "# RecSys metrics\n",
    "k = 3\n",
    "ndcg = ndcg_at_k(records, k)\n",
    "mapk = map_at_k(records, k)\n",
    "\n",
    "import numpy as np\n",
    "avg_return = float(np.mean(pnl_returns))\n",
    "\n",
    "print(f\"Model: {model_name}, User: {user_profile.name}\")\n",
    "print(f\"NDCG@{k}: {ndcg:.4f}  MAP@{k}: {mapk:.4f}\")\n",
    "print(f\"Average 3-day return per position: {avg_return:.4f}\")\n",
    "print(f\"Number of test cases: {len(records)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8032b21-d957-4c19-9cf0-72d927f83048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaefa3cb-2aba-46ab-8b02-da5f28c1fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved labeled dataset to: C:\\Users\\user\\Desktop\\recsys_crypto\\data\\processed\\market_features_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.config import DATA_DIR\n",
    "\n",
    "labeled_path = Path(DATA_DIR) / \"processed\" / \"market_features_labeled.csv\"\n",
    "labeled_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_labeled.to_csv(labeled_path, index=False)\n",
    "print(\"Saved labeled dataset to:\", labeled_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4765b805-157a-4e18-8e99-7bf46144afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/recsys_metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/recsys_metrics.py\n",
    "from typing import List, Dict\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def _relevance(action: str, true_action: str) -> int:\n",
    "    return int(action == true_action)\n",
    "\n",
    "\n",
    "def ndcg_at_k(records: List[Dict], k: int) -> float:\n",
    "    scores = []\n",
    "    for rec in records:\n",
    "        ranking = rec[\"ranking\"][:k]\n",
    "        true = rec[\"true\"]\n",
    "        dcg = 0.0\n",
    "        for i, a in enumerate(ranking):\n",
    "            rel = _relevance(a, true)\n",
    "            dcg += (2**rel - 1) / math.log2(i + 2)\n",
    "        idcg = (2**1 - 1) / math.log2(1 + 1)\n",
    "        scores.append(dcg / idcg if idcg > 0 else 0.0)\n",
    "    return sum(scores) / len(scores) if scores else 0.0\n",
    "\n",
    "\n",
    "def map_at_k(records: List[Dict], k: int) -> float:\n",
    "    aps = []\n",
    "    for rec in records:\n",
    "        ranking = rec[\"ranking\"][:k]\n",
    "        true = rec[\"true\"]\n",
    "        if true in ranking:\n",
    "            idx = ranking.index(true)\n",
    "            aps.append(1.0 / (idx + 1))\n",
    "        else:\n",
    "            aps.append(0.0)\n",
    "    return sum(aps) / len(aps) if aps else 0.0\n",
    "\n",
    "\n",
    "def diversity(records: List[Dict]) -> float:\n",
    "    top1 = [r[\"ranking\"][0] for r in records if r[\"ranking\"]]\n",
    "    counts = Counter(top1)\n",
    "    total = sum(counts.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    entropy = -sum((c/total) * math.log2(c/total) for c in counts.values())\n",
    "    max_entropy = math.log2(len(counts)) if counts else 1.0\n",
    "    return entropy / max_entropy if max_entropy > 0 else 0.0\n",
    "\n",
    "\n",
    "def coverage(records: List[Dict]) -> float:\n",
    "    \"\"\"\n",
    "    Very simple coverage: fraction of queries where we produced a non-empty ranking.\n",
    "    If you add asset info into each record, you can refine this to 'fraction of assets covered'.\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        return 0.0\n",
    "    non_empty = sum(1 for r in records if r.get(\"ranking\"))\n",
    "    return non_empty / len(records)\n",
    "\n",
    "\n",
    "def serendipity(records: List[Dict], baseline_top1: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Simple serendipity definition:\n",
    "    - 'Serendipitous' if our top-1 action differs from baseline's top-1,\n",
    "      AND it is actually correct (matches true_action).\n",
    "    - Serendipity = (# serendipitous cases) / (# total cases).\n",
    "    \n",
    "    baseline_top1 should be a list of same length as records,\n",
    "    where each entry is the baseline's top-1 action for that query.\n",
    "    \"\"\"\n",
    "    if not records or not baseline_top1 or len(records) != len(baseline_top1):\n",
    "        return 0.0\n",
    "\n",
    "    serend = 0\n",
    "    total = 0\n",
    "\n",
    "    for rec, base_action in zip(records, baseline_top1):\n",
    "        if not rec.get(\"ranking\"):\n",
    "            continue\n",
    "        top_action = rec[\"ranking\"][0]\n",
    "        true = rec[\"true\"]\n",
    "        total += 1\n",
    "        if top_action != base_action and top_action == true:\n",
    "            serend += 1\n",
    "\n",
    "    return serend / total if total else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3afe2134-8b51-4792-b42b-ccefb190cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/ml_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/ml_models.py\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from .config import DATA_DIR\n",
    "\n",
    "\n",
    "def load_labeled_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the labeled market features dataset with columns including:\n",
    "    timestamp, asset, technical indicators, future_return, true_action, ...\n",
    "    \"\"\"\n",
    "    path = Path(DATA_DIR) / \"processed\" / \"market_features_labeled.csv\"\n",
    "    df = pd.read_csv(path, parse_dates=[\"timestamp\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_feature_columns(df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return the list of feature columns (exclude target and obvious ID / leakage columns).\n",
    "    \"\"\"\n",
    "    exclude_cols = [\"timestamp\", \"asset\", \"future_close\", \"future_return\", \"true_action\"]\n",
    "    return [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "\n",
    "def train_classifier(df_train: pd.DataFrame) -> Tuple[RandomForestClassifier, List[str]]:\n",
    "    \"\"\"\n",
    "    Train a RandomForestClassifier on the training portion only.\n",
    "    This function does NOT touch the test data.\n",
    "    \"\"\"\n",
    "    df_train = df_train.sort_values([\"timestamp\", \"asset\"]).reset_index(drop=True)\n",
    "\n",
    "    feature_cols = get_feature_columns(df_train)\n",
    "    X_train = df_train[feature_cols]\n",
    "    y_train = df_train[\"true_action\"]\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf, feature_cols\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Debug: train on full dataset and print sizes (not used in backtest).\n",
    "    df_all = load_labeled_data()\n",
    "    clf, feat_cols = train_classifier(df_all)\n",
    "    print(\"Trained RandomForest on\", len(df_all), \"rows.\")\n",
    "    print(\"Number of features:\", len(feat_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca34262-9459-467a-a63d-73e944619036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/backtest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/backtest.py\n",
    "# src/backtest.py\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from .ml_models import (\n",
    "    load_labeled_data,\n",
    "    get_feature_columns,\n",
    "    train_classifier,\n",
    ")\n",
    "from .user_model import UserProfile\n",
    "from .hybrid_engine import compute_final_scores, rank_actions\n",
    "from .recsys_metrics import (\n",
    "    ndcg_at_k,\n",
    "    map_at_k,\n",
    "    diversity,\n",
    "    coverage,\n",
    "    serendipity,\n",
    ")\n",
    "from . import ollama_client as oc\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Train / test time split\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "def time_split(\n",
    "    df: pd.DataFrame,\n",
    "    train_ratio: float = 0.7,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Time-based split to avoid information leakage.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values([\"timestamp\", \"asset\"])\n",
    "    n = len(df_sorted)\n",
    "    split_idx = int(n * train_ratio)\n",
    "    df_train = df_sorted.iloc[:split_idx].copy()\n",
    "    df_test = df_sorted.iloc[split_idx:].copy()\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "# -------------\n",
    "# PnL & equity\n",
    "# -------------\n",
    "\n",
    "\n",
    "def compute_pnl(top_action: str, future_return: float) -> float:\n",
    "    \"\"\"\n",
    "    Simple PnL without transaction cost:\n",
    "    - Buy  -> +future_return\n",
    "    - Sell -> -future_return (assume perfect shorting)\n",
    "    - Hold -> 0\n",
    "    \"\"\"\n",
    "    if top_action == \"Buy\":\n",
    "        return float(future_return)\n",
    "    if top_action == \"Sell\":\n",
    "        return float(-future_return)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def compute_pnl_with_costs(\n",
    "    top_action: str,\n",
    "    future_return: float,\n",
    "    fee_rate: float = 0.001,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    PnL with simple transaction costs:\n",
    "    - Buy:  profit  future_return - 2 * fee_rate (entry + exit)\n",
    "    - Sell: profit  -future_return - 2 * fee_rate\n",
    "    - Hold: 0\n",
    "    \"\"\"\n",
    "    if top_action == \"Buy\":\n",
    "        gross = float(future_return)\n",
    "    elif top_action == \"Sell\":\n",
    "        gross = float(-future_return)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "    cost = 2.0 * fee_rate\n",
    "    return gross - cost\n",
    "\n",
    "\n",
    "def equity_curve(\n",
    "    pnls: List[float],\n",
    "    initial_capital: float = 1.0,\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    Convert per-trade returns into an equity curve,\n",
    "    assuming full capital allocated on each trade.\n",
    "    \"\"\"\n",
    "    equity = float(initial_capital)\n",
    "    curve = [equity]\n",
    "    for r in pnls:\n",
    "        equity *= (1.0 + r)\n",
    "        curve.append(equity)\n",
    "    return curve\n",
    "\n",
    "\n",
    "def equity_stats(curve: List[float]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute simple equity stats:\n",
    "    - final: final capital\n",
    "    - max_drawdown: minimum (equity / running_max - 1)\n",
    "    \"\"\"\n",
    "    if not curve:\n",
    "        return {\"final\": 0.0, \"max_drawdown\": 0.0}\n",
    "\n",
    "    arr = np.array(curve, dtype=float)\n",
    "    running_max = np.maximum.accumulate(arr)\n",
    "    drawdown = (arr - running_max) / running_max\n",
    "    max_dd = float(drawdown.min()) if len(drawdown) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"final\": float(arr[-1]),\n",
    "        \"max_drawdown\": max_dd,\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# LLM parallel helper\n",
    "# -------------------\n",
    "\n",
    "\n",
    "def _llm_call_single(model_name: str, row_dict: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Simple wrapper to call Ollama for one row_dict.\n",
    "    \"\"\"\n",
    "    return oc.ask_ollama(model_name, row_dict)\n",
    "\n",
    "\n",
    "def call_llm_parallel(\n",
    "    model_name: str,\n",
    "    rows: List[Dict],\n",
    "    max_workers: int = 4,\n",
    ") -> Tuple[List[Optional[Dict]], int]:\n",
    "    \"\"\"\n",
    "    Call LLM in parallel for a list of row dicts.\n",
    "\n",
    "    Returns:\n",
    "        outputs: list of LLM outputs (or None on error) aligned with rows\n",
    "        error_count: how many calls failed\n",
    "    \"\"\"\n",
    "    outputs: List[Optional[Dict]] = [None] * len(rows)\n",
    "    error_count = 0\n",
    "\n",
    "    if max_workers <= 1 or len(rows) <= 1:\n",
    "        # Fallback to sequential for small cases / debugging\n",
    "        for i, rd in enumerate(rows):\n",
    "            try:\n",
    "                outputs[i] = _llm_call_single(model_name, rd)\n",
    "            except Exception:\n",
    "                error_count += 1\n",
    "        return outputs, error_count\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = {\n",
    "            ex.submit(_llm_call_single, model_name, rd): i\n",
    "            for i, rd in enumerate(rows)\n",
    "        }\n",
    "        for fut in as_completed(futures):\n",
    "            i = futures[fut]\n",
    "            try:\n",
    "                outputs[i] = fut.result()\n",
    "            except Exception:\n",
    "                error_count += 1\n",
    "\n",
    "    return outputs, error_count\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Simple pattern heuristics\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "def heuristic_pattern_support(row: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Simple rule-based pattern support based on RSI and MACD.\n",
    "\n",
    "    This is a placeholder for real SPMF-based pattern mining,\n",
    "    but already injects pattern information into the hybrid engine.\n",
    "    \"\"\"\n",
    "    rsi = float(row.get(\"rsi\", 50.0))\n",
    "    macd = float(row.get(\"macd\", 0.0))\n",
    "\n",
    "    # Start from neutral\n",
    "    support = {\"Buy\": 1.0, \"Hold\": 1.0, \"Sell\": 1.0}\n",
    "\n",
    "    # RSI-based pattern\n",
    "    if rsi < 30:\n",
    "        # Oversold -> support Buy\n",
    "        support[\"Buy\"] += 2.0\n",
    "    elif rsi > 70:\n",
    "        # Overbought -> support Sell\n",
    "        support[\"Sell\"] += 2.0\n",
    "    else:\n",
    "        support[\"Hold\"] += 1.0\n",
    "\n",
    "    # MACD-based pattern\n",
    "    if macd > 0:\n",
    "        support[\"Buy\"] += 1.0\n",
    "    elif macd < 0:\n",
    "        support[\"Sell\"] += 1.0\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "    total = sum(support.values()) or 1.0\n",
    "    for k in support:\n",
    "        support[k] /= total\n",
    "\n",
    "    return support\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# ML-only backtest\n",
    "# ----------------\n",
    "\n",
    "\n",
    "def backtest_ml_only(\n",
    "    model,\n",
    "    feature_cols: List[str],\n",
    "    df_test: pd.DataFrame,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Baseline: ML-only ranking from RandomForest predicted probabilities.\n",
    "    \"\"\"\n",
    "    records: List[Dict] = []\n",
    "    pnls: List[float] = []\n",
    "    top1_actions: List[str] = []\n",
    "\n",
    "    df_sorted = df_test.sort_values([\"timestamp\", \"asset\"])\n",
    "    X = df_sorted[feature_cols]\n",
    "    y_true = df_sorted[\"true_action\"].tolist()\n",
    "    fut_ret = df_sorted[\"future_return\"].tolist()\n",
    "\n",
    "    probas = model.predict_proba(X)\n",
    "    classes = list(model.classes_)\n",
    "\n",
    "    for i in range(len(df_sorted)):\n",
    "        proba = probas[i]\n",
    "        ml_conf = {cls: float(p) for cls, p in zip(classes, proba)}\n",
    "        for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "            ml_conf.setdefault(a, 0.0)\n",
    "\n",
    "        # For ML-only, we can just treat ml_conf as final scores\n",
    "        scores = ml_conf\n",
    "        ranking = sorted(scores.keys(), key=lambda k: scores[k], reverse=True)\n",
    "        true_action = y_true[i]\n",
    "\n",
    "        records.append({\"ranking\": ranking, \"true\": true_action})\n",
    "        top1_actions.append(ranking[0])\n",
    "\n",
    "        # Use PnL with costs for more realism\n",
    "        pnl = compute_pnl_with_costs(ranking[0], fut_ret[i], fee_rate=0.001)\n",
    "        pnls.append(pnl)\n",
    "\n",
    "    k = 3\n",
    "    ndcg_val = ndcg_at_k(records, k)\n",
    "    map_val = map_at_k(records, k)\n",
    "    div = diversity(records)\n",
    "    cov = coverage(records)\n",
    "    avg_pnl = float(np.mean(pnls)) if pnls else 0.0\n",
    "\n",
    "    curve = equity_curve(pnls, initial_capital=1.0)\n",
    "    eq = equity_stats(curve)\n",
    "\n",
    "    metrics = {\n",
    "        \"mode\": \"ml_only\",\n",
    "        \"ndcg\": ndcg_val,\n",
    "        \"map\": map_val,\n",
    "        \"diversity\": div,\n",
    "        \"coverage\": cov,\n",
    "        \"serendipity\": None,\n",
    "        \"avg_pnl\": avg_pnl,\n",
    "        \"equity_final\": eq[\"final\"],\n",
    "        \"equity_max_drawdown\": eq[\"max_drawdown\"],\n",
    "        \"n\": len(records),\n",
    "        \"baseline_top1\": top1_actions,\n",
    "        \"records\": records,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# LLM-only backtest\n",
    "# -----------------\n",
    "\n",
    "\n",
    "def backtest_llm_only(\n",
    "    model_name: str,\n",
    "    df_test: pd.DataFrame,\n",
    "    user: UserProfile,\n",
    "    max_workers: int = 4,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    LLM-only:\n",
    "    - Ignore ML scores, only take LLM 'action_scores'.\n",
    "    - If Ollama fails for a row, fall back to neutral scores.\n",
    "    - Uses parallel calls to the LLM for efficiency.\n",
    "    \"\"\"\n",
    "    records: List[Dict] = []\n",
    "    pnls: List[float] = []\n",
    "    top1_actions: List[str] = []\n",
    "\n",
    "    # Materialize rows once\n",
    "    rows = list(df_test.iterrows())\n",
    "    row_dicts = [row.to_dict() for _, row in rows]\n",
    "\n",
    "    # Parallel LLM calls\n",
    "    llm_outputs, error_count = call_llm_parallel(\n",
    "        model_name=model_name,\n",
    "        rows=row_dicts,\n",
    "        max_workers=max_workers,\n",
    "    )\n",
    "\n",
    "    for idx, (pandas_idx, row) in enumerate(rows):\n",
    "        out = llm_outputs[idx]\n",
    "\n",
    "        if out is None:\n",
    "            # LLM failed for this row\n",
    "            scores = {\"Buy\": 1.0 / 3.0, \"Hold\": 1.0 / 3.0, \"Sell\": 1.0 / 3.0}\n",
    "        else:\n",
    "            scores = out.get(\"action_scores\", {})\n",
    "        for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "            scores.setdefault(a, 0.0)\n",
    "\n",
    "        final_scores = compute_final_scores(\n",
    "            ml_conf={\"Buy\": 0.0, \"Hold\": 0.0, \"Sell\": 0.0},\n",
    "            llm_score=scores,\n",
    "            pattern_support={\"Buy\": 0.0, \"Hold\": 0.0, \"Sell\": 0.0},\n",
    "            alpha=0.0,\n",
    "            beta=1.0,\n",
    "            gamma=0.0,\n",
    "            user=user,\n",
    "        )\n",
    "        ranking = [a for a, _ in rank_actions(final_scores)]\n",
    "        true_action = row[\"true_action\"]\n",
    "\n",
    "        records.append({\"ranking\": ranking, \"true\": true_action})\n",
    "        top1_actions.append(ranking[0])\n",
    "\n",
    "        pnl = compute_pnl_with_costs(ranking[0], row[\"future_return\"], fee_rate=0.001)\n",
    "        pnls.append(pnl)\n",
    "\n",
    "    k = 3\n",
    "    ndcg_val = ndcg_at_k(records, k)\n",
    "    map_val = map_at_k(records, k)\n",
    "    div = diversity(records)\n",
    "    cov = coverage(records)\n",
    "    avg_pnl = float(np.mean(pnls)) if pnls else 0.0\n",
    "\n",
    "    curve = equity_curve(pnls, initial_capital=1.0)\n",
    "    eq = equity_stats(curve)\n",
    "\n",
    "    metrics = {\n",
    "        \"mode\": f\"llm_only_{model_name}\",\n",
    "        \"ndcg\": ndcg_val,\n",
    "        \"map\": map_val,\n",
    "        \"diversity\": div,\n",
    "        \"coverage\": cov,\n",
    "        \"serendipity\": None,\n",
    "        \"avg_pnl\": avg_pnl,\n",
    "        \"equity_final\": eq[\"final\"],\n",
    "        \"equity_max_drawdown\": eq[\"max_drawdown\"],\n",
    "        \"n\": len(records),\n",
    "        \"baseline_top1\": top1_actions,\n",
    "        \"records\": records,\n",
    "        \"llm_errors\": error_count,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Hybrid backtest\n",
    "# -------------------\n",
    "\n",
    "\n",
    "def backtest_hybrid(\n",
    "    model,\n",
    "    feature_cols: List[str],\n",
    "    df_test: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    user: UserProfile,\n",
    "    alpha: float = 0.4,\n",
    "    beta: float = 0.4,\n",
    "    gamma: float = 0.2,\n",
    "    ml_baseline_top1: Optional[List[str]] = None,\n",
    "    max_workers: int = 4,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Hybrid:\n",
    "    - Combine ML probabilities, LLM scores and pattern support.\n",
    "    - If LLM fails, fall back to ML-only for that row.\n",
    "    - Uses parallel LLM calls for efficiency.\n",
    "    \"\"\"\n",
    "    records: List[Dict] = []\n",
    "    pnls: List[float] = []\n",
    "    hybrid_top1: List[str] = []\n",
    "\n",
    "    # Materialize rows once\n",
    "    rows = list(df_test.iterrows())\n",
    "    row_dicts = [row.to_dict() for _, row in rows]\n",
    "\n",
    "    # Parallel LLM calls\n",
    "    llm_outputs, error_count = call_llm_parallel(\n",
    "        model_name=model_name,\n",
    "        rows=row_dicts,\n",
    "        max_workers=max_workers,\n",
    "    )\n",
    "\n",
    "    for idx, (pandas_idx, row) in enumerate(rows):\n",
    "        # ML confidences\n",
    "        X_row = row[feature_cols].to_frame().T\n",
    "        proba = model.predict_proba(X_row)[0]\n",
    "        classes = model.classes_\n",
    "        ml_conf = {cls: float(p) for cls, p in zip(classes, proba)}\n",
    "        for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "            ml_conf.setdefault(a, 0.0)\n",
    "\n",
    "        # LLM scores\n",
    "        out = llm_outputs[idx]\n",
    "        if out is None:\n",
    "            llm_scores = {\"Buy\": 0.0, \"Hold\": 0.0, \"Sell\": 0.0}\n",
    "        else:\n",
    "            llm_scores = out.get(\"action_scores\", {})\n",
    "        for a in [\"Buy\", \"Hold\", \"Sell\"]:\n",
    "            llm_scores.setdefault(a, 0.0)\n",
    "\n",
    "        # Pattern support (heuristic for now)\n",
    "        pattern_support = heuristic_pattern_support(row)\n",
    "\n",
    "        final_scores = compute_final_scores(\n",
    "            ml_conf=ml_conf,\n",
    "            llm_score=llm_scores,\n",
    "            pattern_support=pattern_support,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            gamma=gamma,\n",
    "            user=user,\n",
    "        )\n",
    "        ranking = [a for a, _ in rank_actions(final_scores)]\n",
    "        true_action = row[\"true_action\"]\n",
    "\n",
    "        records.append({\"ranking\": ranking, \"true\": true_action})\n",
    "        hybrid_top1.append(ranking[0])\n",
    "\n",
    "        pnl = compute_pnl_with_costs(ranking[0], row[\"future_return\"], fee_rate=0.001)\n",
    "        pnls.append(pnl)\n",
    "\n",
    "    k = 3\n",
    "    ndcg_val = ndcg_at_k(records, k)\n",
    "    map_val = map_at_k(records, k)\n",
    "    div = diversity(records)\n",
    "    cov = coverage(records)\n",
    "    avg_pnl = float(np.mean(pnls)) if pnls else 0.0\n",
    "\n",
    "    curve = equity_curve(pnls, initial_capital=1.0)\n",
    "    eq = equity_stats(curve)\n",
    "\n",
    "    ser = None\n",
    "    if ml_baseline_top1 is not None:\n",
    "        ser = serendipity(records, ml_baseline_top1)\n",
    "\n",
    "    metrics = {\n",
    "        \"mode\": f\"hybrid_{model_name}\",\n",
    "        \"ndcg\": ndcg_val,\n",
    "        \"map\": map_val,\n",
    "        \"diversity\": div,\n",
    "        \"coverage\": cov,\n",
    "        \"serendipity\": ser,\n",
    "        \"avg_pnl\": avg_pnl,\n",
    "        \"equity_final\": eq[\"final\"],\n",
    "        \"equity_max_drawdown\": eq[\"max_drawdown\"],\n",
    "        \"n\": len(records),\n",
    "        \"hybrid_top1\": hybrid_top1,\n",
    "        \"records\": records,\n",
    "        \"llm_errors\": error_count,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# --------------\n",
    "# Top-level run\n",
    "# --------------\n",
    "\n",
    "\n",
    "def run_all(\n",
    "    model_name: str = \"gemma3:4b\",\n",
    "    user_type: str = \"moderate\",\n",
    "    max_eval_rows: int = 300,\n",
    "    llm_max_workers: int = 4,\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    End-to-end:\n",
    "    - Load labeled data\n",
    "    - Time-based split\n",
    "    - Train RF classifier\n",
    "    - Sample subset of test period\n",
    "    - Run ML-only, LLM-only, Hybrid backtests\n",
    "\n",
    "    Returns a dict with three metrics dicts.\n",
    "    \"\"\"\n",
    "    df = load_labeled_data()\n",
    "    df_train, df_test = time_split(df, train_ratio=0.7)\n",
    "    feature_cols = get_feature_columns(df_train)\n",
    "\n",
    "    clf = train_classifier(df_train)\n",
    "\n",
    "    # Choose user profile\n",
    "    user = UserProfile.from_type(user_type)\n",
    "\n",
    "    # Sample subset of test period for evaluation\n",
    "    df_eval = df_test.sample(\n",
    "        n=min(max_eval_rows, len(df_test)), random_state=42\n",
    "    ).sort_values([\"timestamp\", \"asset\"])\n",
    "\n",
    "    ml_m = backtest_ml_only(clf, feature_cols, df_eval)\n",
    "    llm_m = backtest_llm_only(\n",
    "        model_name,\n",
    "        df_eval,\n",
    "        user=user,\n",
    "        max_workers=llm_max_workers,\n",
    "    )\n",
    "    hyb_m = backtest_hybrid(\n",
    "        clf,\n",
    "        feature_cols,\n",
    "        df_eval,\n",
    "        model_name,\n",
    "        user=user,\n",
    "        alpha=0.4,\n",
    "        beta=0.4,\n",
    "        gamma=0.2,\n",
    "        ml_baseline_top1=ml_m[\"baseline_top1\"],\n",
    "        max_workers=llm_max_workers,\n",
    "    )\n",
    "\n",
    "    # Simple printout (optional)\n",
    "    print(\"=== ML-only ===\")\n",
    "    print(\n",
    "        f\"NDCG={ml_m['ndcg']:.4f}, MAP={ml_m['map']:.4f}, \"\n",
    "        f\"Div={ml_m['diversity']:.4f}, Cov={ml_m['coverage']:.4f}, \"\n",
    "        f\"AvgPnL={ml_m['avg_pnl']:.4f}, FinalEq={ml_m['equity_final']:.4f}, \"\n",
    "        f\"MaxDD={ml_m['equity_max_drawdown']:.4f}\"\n",
    "    )\n",
    "    print(\"=== LLM-only ===\")\n",
    "    print(\n",
    "        f\"NDCG={llm_m['ndcg']:.4f}, MAP={llm_m['map']:.4f}, \"\n",
    "        f\"Div={llm_m['diversity']:.4f}, Cov={llm_m['coverage']:.4f}, \"\n",
    "        f\"AvgPnL={llm_m['avg_pnl']:.4f}, FinalEq={llm_m['equity_final']:.4f}, \"\n",
    "        f\"MaxDD={llm_m['equity_max_drawdown']:.4f}, LLM_errors={llm_m['llm_errors']}\"\n",
    "    )\n",
    "    print(\"=== Hybrid ===\")\n",
    "    print(\n",
    "        f\"NDCG={hyb_m['ndcg']:.4f}, MAP={hyb_m['map']:.4f}, \"\n",
    "        f\"Div={hyb_m['diversity']:.4f}, Cov={hyb_m['coverage']:.4f}, \"\n",
    "        f\"Ser={hyb_m['serendipity']}, AvgPnL={hyb_m['avg_pnl']:.4f}, \"\n",
    "        f\"FinalEq={hyb_m['equity_final']:.4f}, MaxDD={hyb_m['equity_max_drawdown']:.4f}, \"\n",
    "        f\"LLM_errors={hyb_m['llm_errors']}\"\n",
    "    )\n",
    "\n",
    "    return {\"ml\": ml_m, \"llm\": llm_m, \"hybrid\": hyb_m}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7d5bcd2-885e-4c76-bf66-e3c7098e6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled path: C:\\Users\\user\\Desktop\\recsys_crypto\\data\\processed\\market_features_labeled.csv exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.config import DATA_DIR\n",
    "\n",
    "labeled_path = Path(DATA_DIR) / \"processed\" / \"market_features_labeled.csv\"\n",
    "print(\"Labeled path:\", labeled_path, \"exists:\", labeled_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "453121ca-ce4a-4b3a-83d9-131faef19b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classifier to: C:\\Users\\user\\Desktop\\recsys_crypto\\models\\ml\\clf_true_action.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.ml_models import train_and_save_classifier\n",
    "\n",
    "clf, feat_cols = train_and_save_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ed11d-3d58-441e-8e91-560b0652e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM ERROR llama3 at row 54] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "[LLM ERROR llama3 at row 55] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "[LLM ERROR llama3 at row 56] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "[LLM ERROR llama3 at row 57] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "[LLM ERROR llama3 at row 59] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n",
      "[LLM ERROR llama3 at row 77] 500 Server Error: Internal Server Error for url: http://localhost:11434/api/chat\n"
     ]
    }
   ],
   "source": [
    "from src.backtest import run_all\n",
    "\n",
    "ml_m, llm_m, hyb_m = run_all(model_name=\"llama3\", user_type=\"moderate\")\n",
    "ml_m, llm_m, hyb_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750b3ca-4b23-46dc-9c73-321d0956e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import backtest\n",
    "import importlib; importlib.reload(backtest)\n",
    "\n",
    "models = [\"gemma3:4b\", \"phi\", \"llama3\"]  # 'llama3' == 'llama3:latest'\n",
    "\n",
    "results = {}\n",
    "\n",
    "for m in models:\n",
    "    print(f\"\\n### Running backtest for {m} ###\")\n",
    "    ml_m, llm_m, hyb_m = backtest.run_all(model_name=m, user_type=\"moderate\")\n",
    "    results[m] = {\"ml\": ml_m, \"llm\": llm_m, \"hybrid\": hyb_m}\n",
    "    print(\"ML-only  NDCG:\", ml_m[\"ndcg\"], \"MAP:\", ml_m[\"map\"], \"Avg PnL:\", ml_m[\"avg_pnl\"])\n",
    "    print(\"LLM-only NDCG:\", llm_m[\"ndcg\"], \"MAP:\", llm_m[\"map\"], \"Avg PnL:\", llm_m[\"avg_pnl\"],\n",
    "          \"LLM errors:\", llm_m.get(\"llm_errors\", 0))\n",
    "    print(\"Hybrid   NDCG:\", hyb_m[\"ndcg\"], \"MAP:\", hyb_m[\"map\"], \"Avg PnL:\", hyb_m[\"avg_pnl\"],\n",
    "          \"Serendipity:\", hyb_m[\"serendipity\"], \"LLM errors:\", hyb_m.get(\"llm_errors\", 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539f83bb-acf3-4937-a92b-29eb6a268537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root = parent of notebooks/\n",
    "root = Path(\"..\").resolve()\n",
    "sys.path.append(str(root / \"src\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071b71c2-46a1-4a2a-92a5-0a3de342ea33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbacktest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_all\n\u001b[0;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m run_all(\n\u001b[0;32m      4\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma3:4b\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# or whatever Ollama model you use\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     user_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoderate\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \u001b[38;5;66;03m# \"conservative\", \"moderate\", \"aggressive\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     max_eval_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,        \u001b[38;5;66;03m# smaller at first to test speed\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     llm_max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,        \u001b[38;5;66;03m# parallel LLM calls\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32m~\\Desktop\\recsys_crypto\\src\\backtest.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     load_labeled_data,\n\u001b[0;32m     12\u001b[0m     get_feature_columns,\n\u001b[0;32m     13\u001b[0m     train_classifier,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserProfile\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhybrid_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_final_scores, rank_actions\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from backtest import run_all\n",
    "\n",
    "results = run_all(\n",
    "    model_name=\"gemma3:4b\",   # or whatever Ollama model you use\n",
    "    user_type=\"moderate\",     # \"conservative\", \"moderate\", \"aggressive\"\n",
    "    max_eval_rows=200,        # smaller at first to test speed\n",
    "    llm_max_workers=4,        # parallel LLM calls\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9356224f-fe5a-40c3-8804-1c09f0599e6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1666828745.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    C:\\Users\\user\\Desktop\\recsys_crypto\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "C:\\Users\\user\\Desktop\\recsys_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8539fdc4-b323-4059-b026-97f6b643cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\user\\Desktop\\recsys_crypto\n",
      "In sys.path: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# REAL project root (one level ABOVE notebooks)\n",
    "project_root = Path(r\"C:\\Users\\user\\Desktop\\recsys_crypto\").resolve()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"In sys.path:\", str(project_root) in sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38846c1a-be96-4e2e-9ccf-538d21f44b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.ml_models import load_labeled_data\n",
    "import src.ollama_client as oc\n",
    "from src.user_model import UserProfile\n",
    "from src.hybrid_engine import compute_final_scores, rank_actions\n",
    "from src.backtest import heuristic_pattern_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d55ea06-9b2b-4679-829f-5b57f63217d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset: XRPUSDT Time: 2025-11-30 22:00:00\n",
      "True action: Hold\n",
      "LLM raw: {'Buy': 0.4, 'Hold': 0.5, 'Sell': 0.1}\n",
      "Pattern support: {'Buy': 0.2, 'Hold': 0.4, 'Sell': 0.4}\n",
      "Final ranking: [('Hold', 0.4769230769230769), ('Buy', 0.35384615384615387), ('Sell', 0.1692307692307692)]\n",
      "----------------------------------------\n",
      "Asset: AVAXUSDT Time: 2025-11-26 00:00:00\n",
      "True action: Buy\n",
      "LLM raw: {'Buy': 0.2, 'Hold': 0.7, 'Sell': 0.1}\n",
      "Pattern support: {'Buy': 0.3333333333333333, 'Hold': 0.16666666666666666, 'Sell': 0.5}\n",
      "Final ranking: [('Hold', 0.5769230769230769), ('Buy', 0.23076923076923075), ('Sell', 0.1923076923076923)]\n",
      "----------------------------------------\n",
      "Asset: ETHUSDT Time: 2025-11-21 17:00:00\n",
      "True action: Buy\n",
      "LLM raw: {'Buy': 0.4, 'Hold': 0.4, 'Sell': 0.2}\n",
      "Pattern support: {'Buy': 0.2, 'Hold': 0.4, 'Sell': 0.4}\n",
      "Final ranking: [('Hold', 0.4), ('Buy', 0.35384615384615387), ('Sell', 0.24615384615384614)]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = load_labeled_data()\n",
    "\n",
    "# Take first 3 rows as examples\n",
    "sample = df.sample(3, random_state=0)\n",
    "\n",
    "user = UserProfile.from_type(\"moderate\")\n",
    "\n",
    "for _, row in sample.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "\n",
    "    # Call LLM once\n",
    "    out = oc.ask_ollama(\"gemma3:4b\", row_dict)\n",
    "    llm_scores = out[\"action_scores\"]\n",
    "\n",
    "    # For demo, we ignore ML and use only LLM + pattern\n",
    "    pattern_support = heuristic_pattern_support(row)\n",
    "\n",
    "    final_scores = compute_final_scores(\n",
    "        ml_conf={\"Buy\": 0.0, \"Hold\": 0.0, \"Sell\": 0.0},\n",
    "        llm_score=llm_scores,\n",
    "        pattern_support=pattern_support,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "        gamma=0.3,\n",
    "        user=user,\n",
    "    )\n",
    "    ranking = rank_actions(final_scores)\n",
    "\n",
    "    print(\"Asset:\", row[\"asset\"], \"Time:\", row[\"timestamp\"])\n",
    "    print(\"True action:\", row[\"true_action\"])\n",
    "    print(\"LLM raw:\", llm_scores)\n",
    "    print(\"Pattern support:\", pattern_support)\n",
    "    print(\"Final ranking:\", ranking)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9132e0b-77c2-47f6-82c3-38badae5a46f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_classifier() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbacktest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_all\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# You can wrap run_all to return the base variants we care about\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results_moderate \u001b[38;5;241m=\u001b[39m \u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma3:4b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# or your LLM model\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmoderate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# middle risk\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_eval_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_max_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m results_moderate\n",
      "File \u001b[1;32m~\\Desktop\\recsys_crypto\\src\\backtest.py:510\u001b[0m, in \u001b[0;36mrun_all\u001b[1;34m(model_name, user_type, max_eval_rows, llm_max_workers)\u001b[0m\n\u001b[0;32m    507\u001b[0m df_train, df_test \u001b[38;5;241m=\u001b[39m time_split(df, train_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m    508\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m get_feature_columns(df_train)\n\u001b[1;32m--> 510\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue_action\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# Choose user profile\u001b[39;00m\n\u001b[0;32m    513\u001b[0m user \u001b[38;5;241m=\u001b[39m UserProfile\u001b[38;5;241m.\u001b[39mfrom_type(user_type)\n",
      "\u001b[1;31mTypeError\u001b[0m: train_classifier() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from src.backtest import run_all\n",
    "\n",
    "# You can wrap run_all to return the base variants we care about\n",
    "results_moderate = run_all(\n",
    "    model_name=\"gemma3:4b\",       # or your LLM model\n",
    "    user_type=\"moderate\",         # middle risk\n",
    "    max_eval_rows=300,\n",
    "    llm_max_workers=4,\n",
    ")\n",
    "\n",
    "results_moderate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13017923-d8f7-4fcf-b328-5bc593fae6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
